{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3801d352",
   "metadata": {
    "id": "3801d352"
   },
   "source": [
    "## Домашнее задание : \"Обучение с подкреплением\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c3d037",
   "metadata": {
    "id": "e0c3d037"
   },
   "source": [
    "ФИО: Лапутин Федор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528f5be",
   "metadata": {
    "id": "9528f5be"
   },
   "source": [
    "# Задание 1\n",
    "\n",
    "Обучите алгоритм Q-learning для сред FrozenLake-v1 4x4 и Blackjack-v1, в частности подберите оптимальную alpha.(1 балл)\n",
    "\n",
    "Обучите алгоритм Q-learning для среды FrozenLake-v1 8x8. Придумайте как обойти проблему отсутствия положительных наград в случайных эпизодах игры. (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78f84e",
   "metadata": {},
   "source": [
    "### Решение\n",
    "\n",
    "Для среды FrozenLake-v1 преставлено в файле ```frozenlake_4x4.py```\n",
    "\n",
    "Поскольку при любых alpha алгоритм сходится очень хорошо, то посчитаем средний ревард который получают агенты за все эпизоды, соответсвенно, чем больше это значние, тем быстрее сходится алгоритм. Также для численной стабильности при достижении min epsilone, alpha уменьшался на порядок.\n",
    "\n",
    "Получим следующую таблицу\n",
    "| Alpha | Mean Reward          |\n",
    "|-------|----------------------|\n",
    "| 0.1   | 67.32921428571429    |\n",
    "| 0.2   | 67.0                 |\n",
    "| 0.3   | 67.39528571428572    |\n",
    "| 0.4   | 67.37878571428571    |\n",
    "| 0.5   | 67.47528571428572    |\n",
    "| 0.6   | 67.49242857142858    |\n",
    "| 0.7   | 66.90192857142857    |\n",
    "| 0.8   | 68.08057142857143    |\n",
    "| 0.9   | 67.41157142857143    |\n",
    "\n",
    "Наиболее удачным оказался ```alpha = 0.8```\n",
    "\n",
    "Ниже предствлен график суммы ревардов за 100 эпизодов для каждого эпизода во время обучения, как мы видим уже после 10_000 итераций алгоритм достигает 100% качества.\n",
    "\n",
    "![Frozen Lake 4x4](frozen_lake4x4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fca36",
   "metadata": {},
   "source": [
    "### Решение\n",
    "\n",
    "Для среды BlackJack-v1 преставлено в файле ```blackjack.py```\n",
    "\n",
    "Получим следующую таблицу\n",
    "| Alpha | Mean Reward          |\n",
    "|-------|----------------------|\n",
    "| 0.1   | 36.80992857142857    |\n",
    "| 0.2   | 36.75342857142857    |\n",
    "| 0.3   | 35.72907142857143    |\n",
    "| 0.4   | 36.001               |\n",
    "| 0.5   | 37.410785714285716   |\n",
    "| 0.6   | 37.96357142857143    |\n",
    "| 0.7   | 36.1905              |\n",
    "| 0.8   | 36.46214285714286    |\n",
    "| 0.9   | 35.90357142857143    |\n",
    "\n",
    "Наиболее удачным оказался ```alpha = 0.6```\n",
    "\n",
    "Ниже предствлен график суммы ревардов за 100 эпизодов для каждого эпизода во время обучения, как мы видим уже качество агента примерно 30-40%.\n",
    "\n",
    "![BlackJack](black_jack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b863c",
   "metadata": {},
   "source": [
    "### Решение\n",
    "\n",
    "Для среды FrozenLake-v1 8х8 преставлено в файле ```frozenlake_8x8.py```\n",
    "\n",
    "Усложним нашу среду, теперь поле будет 8х8 и включим режим скольжения, то есть гном может случайно пойти не в ту сторону. Для это были более точным образом выбраны гипепараметры алгоритма epsilone, отвечающие за рандомные действия, посколько гном итак скользит, то рандомность была немного уменьшена, а также за каждый шаг назначался небольшой штраф -0.0001\n",
    "\n",
    "Получим следующую таблицу\n",
    "| Alpha | Mean Reward          |\n",
    "|-------|----------------------|\n",
    "| 0.001 | 1.0181428571428572   |\n",
    "| 0.01  | 0.5376428571428571   |\n",
    "| 0.1   | 37.14142857142857    |\n",
    "| 0.3   | 34.28328571428571    |\n",
    "| 0.7   | 24.05992857142857    |\n",
    "\n",
    "Наиболее удачным оказался ```alpha = 0.8```\n",
    "\n",
    "Ниже предствлен график суммы ревардов за 100 эпизодов для каждого эпизода во время обучения, приведенное решение позволило получить 60-70% качества.\n",
    "\n",
    "![Frozen Lake 8x8](frozen_lake8x8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0b061",
   "metadata": {
    "id": "0fd0b061"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
